{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GDSC INTRODUCTION TO AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will cover turorial lessons and then exercises to learn basic AI concepts and popular algorithms. \n",
    "\n",
    "Let's begin with a brief AI recap.\n",
    "\n",
    "What's AI about: Systems/machines/robots mimicking human intelligence\n",
    "\n",
    "Example:\n",
    "Customer service chatbots\n",
    "Recommender Systems\n",
    "Self driving cars\n",
    "\n",
    "<b>Fields in AI </b>\n",
    "\n",
    "<b>Machine Learning:</b> computers the potential to learn without being programmed\n",
    "<b>Neural Networks:</b> imitates operation of human brain\n",
    "<b>Deep Learning:</b> selects “best” of several methods to produce desirable output\n",
    "<b>Cognitive Processing:</b> complex task completion or problem solving between man and machine\n",
    "<b>Computer Vision:</b> machines interpret visual data\n",
    "<b>Natural Language Processing:</b> communication between human and machine using natural language"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Algorithms</b>\n",
    "- Regression\n",
    "- Decision Trees\n",
    "- Random Forest\n",
    "- Simple NeuraL Networks\n",
    "- Convolutional Neural Networks\n",
    "\n",
    "These are some algorithms, useful depending on the kind of problem you are trying to solve. \n",
    "\n",
    "For the purposes of this lesson we will practice building Machine Learning models and just mention the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>MACHINE LEARNING</b>\n",
    "\n",
    "What is machine learning though? How can we make a computer make decisions on its own without having to instruct \n",
    "it every single time it encouters a problem. That's the question machine learning seeks to answer. It is a combination of statistics/modelling and computer science concepts to help machines learn and from situations and come up with solutions without assistance. \n",
    "\n",
    "there are 3 popular ways of teaching machines, in other words, what is the best way for a machine to learn most effectively in order to solve an existing problem.\n",
    "- Supervised Learning: \n",
    "    Labelled data is provided to our machine, it studies this data very well such that when it is given new set of unlabelled data, it understands it and is able to make a decision on it based on what it learned. Used in problimes like weathe forcasting, spam detection, pricing prediction. \n",
    "    Types - Regression, classification, support vector machines, random forests\n",
    "- Unsupervised Learning:the machine learns from unlabelled data. It uses methods like clustering or association to learn the data and then use this knowledge to inform decisions about new unlabelled data. Useful in solving problems such as anomaly detection, medical imaging etc\n",
    "   Types: Association, Classification \n",
    "- Reinforcement Learning: The machines acts and gets rewards for it's action.depending on the reward it will know if that action should be carried out in that situation or not. Very widely used in solving problems such as self driving cars. It is very widely used in multiple areas. \n",
    "\n",
    "We will look at some types of supervised learning.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>SUPERVISED LEARNING</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Linear Regression</b>\n",
    "\n",
    " We find the relation between continous variables in dataset.  Here, the objective is to find the best fit line\n",
    "    that will accurately make a prediction. We have a set of independent continous variables and a dependent \n",
    "    numeric variable. \n",
    " \n",
    " Follow the link to read more about linear regression: \n",
    " \n",
    " <b>Steps in Linear Regression</b>\n",
    " \n",
    " 1. Load the data set\n",
    " 2. Build Linear Regression Model\n",
    " 3. Predict using the model\n",
    " 4. Check how well you model made the prediction\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this linear regression tutorial we will work with data from sklearn so you need to be connected to \n",
    "the internet to load the data into the notebook.\n",
    "\n",
    "sklearn has multiple amazing data sets you can use for practice. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Boston Housing Data</b>\n",
    "\n",
    "In this tutorial we will use linear regression to predict the prices of a house with knowledge of the features \n",
    "of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression #linear model from sklearn\n",
    "from sklearn.model_selection import train_test_split #help us split data to dependent and independent variables\n",
    "\n",
    "#load dataset\n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston_dataset = load_boston()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4      5     6       7    8      9     10  \\\n",
       "0  0.00632  18.0  2.31  0.0  0.538  6.575  65.2  4.0900  1.0  296.0  15.3   \n",
       "1  0.02731   0.0  7.07  0.0  0.469  6.421  78.9  4.9671  2.0  242.0  17.8   \n",
       "2  0.02729   0.0  7.07  0.0  0.469  7.185  61.1  4.9671  2.0  242.0  17.8   \n",
       "3  0.03237   0.0  2.18  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4  0.06905   0.0  2.18  0.0  0.458  7.147  54.2  6.0622  3.0  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90  9.14  \n",
       "2  392.83  4.03  \n",
       "3  394.63  2.94  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just for the purposes of viewing the dataset\n",
    "from pandas import *\n",
    "df = DataFrame(boston_dataset.data)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = boston_dataset.target #dependent variable \n",
    "X = boston_dataset.data #independent continous variables/features\n",
    "\n",
    "#split the data into train and test set, use 20% of our dataset for dataset and the remaining 80% for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Build Linear Regression Model\n",
    "#create instance of regression model\n",
    "linr_model = LinearRegression()\n",
    "\n",
    "#fit the model using the training data\n",
    "linr_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model\n",
    "linr_predict = linr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28.99672362 36.02556534 14.81694405 25.03197915 18.76987992 23.25442929\n",
      " 17.66253818 14.34119    23.01320703 20.63245597 24.90850512 18.63883645\n",
      " -6.08842184 21.75834668 19.23922576 26.19319733 20.64773313  5.79472718\n",
      " 40.50033966 17.61289074 27.24909479 30.06625441 11.34179277 24.16077616\n",
      " 17.86058499 15.83609765 22.78148106 14.57704449 22.43626052 19.19631835\n",
      " 22.43383455 25.21979081 25.93909562 17.70162434 16.76911711 16.95125411\n",
      " 31.23340153 20.13246729 23.76579011 24.6322925  13.94204955 32.25576301\n",
      " 42.67251161 17.32745046 27.27618614 16.99310991 14.07009109 25.90341861\n",
      " 20.29485982 29.95339638 21.28860173 34.34451856 16.04739105 26.22562412\n",
      " 39.53939798 22.57950697 18.84531367 32.72531661 25.0673037  12.88628956\n",
      " 22.68221908 30.48287757 31.52626806 15.90148607 20.22094826 16.71089812\n",
      " 20.52384893 25.96356264 30.61607978 11.59783023 20.51232627 27.48111878\n",
      " 11.01962332 15.68096344 23.79316251  6.19929359 21.6039073  41.41377225\n",
      " 18.76548695  8.87931901 20.83076916 13.25620627 20.73963699  9.36482222\n",
      " 23.22444271 31.9155003  19.10228271 25.51579303 29.04256769 20.14358566\n",
      " 25.5859787   5.70159447 20.09474756 14.95069156 12.50395648 20.72635294\n",
      " 24.73957161 -0.164237   13.68486682 16.18359697 22.27621999 24.47902364]\n"
     ]
    }
   ],
   "source": [
    "print(linr_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAMPLE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#save ml models in csv files and compare their performance\n",
    "import joblib \n",
    "\n",
    "admissions_dataset = pd.read_csv(\"/home/kuna/Downloads/bertelsmann/graduate-admissions/Admission_Predict.csv\")# Creating input feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Serial No.</th>\n",
       "      <th>GRE Score</th>\n",
       "      <th>TOEFL Score</th>\n",
       "      <th>University Rating</th>\n",
       "      <th>SOP</th>\n",
       "      <th>LOR</th>\n",
       "      <th>CGPA</th>\n",
       "      <th>Research</th>\n",
       "      <th>Chance of Admit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>337</td>\n",
       "      <td>118</td>\n",
       "      <td>4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>9.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>324</td>\n",
       "      <td>107</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.87</td>\n",
       "      <td>1</td>\n",
       "      <td>0.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>316</td>\n",
       "      <td>104</td>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>8.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>322</td>\n",
       "      <td>110</td>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>8.67</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>314</td>\n",
       "      <td>103</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
       "0           1        337          118                  4  4.5   4.5  9.65   \n",
       "1           2        324          107                  4  4.0   4.5  8.87   \n",
       "2           3        316          104                  3  3.0   3.5  8.00   \n",
       "3           4        322          110                  3  3.5   2.5  8.67   \n",
       "4           5        314          103                  2  2.0   3.0  8.21   \n",
       "\n",
       "   Research  Chance of Admit   \n",
       "0         1              0.92  \n",
       "1         1              0.76  \n",
       "2         1              0.72  \n",
       "3         1              0.80  \n",
       "4         0              0.65  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import *\n",
    "df = DataFrame(admissions_dataset)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7736448934347421"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating features\n",
    "X= admissions_dataset[['GRE Score','TOEFL Score','University Rating','SOP','LOR ', 'CGPA']]\n",
    "# Creating target variable\n",
    "y= admissions_dataset [['Chance of Admit ']] \n",
    "\n",
    "#Creating Train and Test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Feature Scaling</b>\n",
    "Feature has to do with transforming a dataset into a common range of values. This can be done by either [Normalizing](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/) or [Standardizing](https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/) columns in the dataset.\n",
    "\n",
    "Feature scaling is most useful when dealing with ML algorithms that use distance based metrics. We may talk about it when working with SVMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StandardScalar a library for normalizing the input features and independent variables\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "stanc_x= StandardScaler()\n",
    "X_train = stanc_x.fit_transform(X_train)\n",
    "X_test = stanc_x.transform(X_test)\n",
    "\n",
    "#Normalizing the target variable\n",
    "stanc_y= StandardScaler()\n",
    "y_train = stanc_y.fit_transform(y_train)\n",
    "y_test = stanc_y.transform(y_test)\n",
    "\n",
    "#Build Linear Regression Model\n",
    "#create instance of regression model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linreg_model = LinearRegression()# fitting the training data to the Linear Regressor\n",
    "linreg_model.fit(X_train,y_train)# Checking the model coefficients\n",
    "\n",
    "#Predict using the model\n",
    "y_predict = linreg_model.predict(x_test)\n",
    "\n",
    "linreg_model.score(X_test, y_test) #print accuracy of algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use joblib to create a file for the predicted model and compare it with that of the original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output a joblib file for the model\n",
    "joblib.dump(linreg_model, '/home/kuna/Downloads/bertelsmann/joblib_test.sav') \n",
    " \n",
    "# Load the jobllib file\n",
    "linreg_model_load = joblib.load('/home/kuna/Downloads/bertelsmann/joblib_test.sav') \n",
    " \n",
    "# Check that the loaded model is the same as the original\n",
    "assert linreg_model.score(x, y) == linreg_model_load.score(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read more about [assert](https://doc.dataiku.com/dss/latest/machine-learning/ml-assertions.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Logistic Regression</b>\n",
    "\n",
    " Used for classification probems. Output is of form Yes/No, 1/0 etc. We classify items in a data set. Here, the line can be a curve or take any shape, must not necessarily be a straight line so not useful describe linear relationships. We have a set of independent categorical variables and a dependent variable. \n",
    " Uses an activation function known as the sigmoid function to convert a linear regression equation to the logistic regression equation.\n",
    " \n",
    " Follow the link to read more about logistic regression: \n",
    " \n",
    " <b>Steps in Logistic Regression</b>\n",
    " \n",
    " 1. Load the data set\n",
    " 2. Build Logistic Regression Model\n",
    " 3. Predict using the model\n",
    " 4. Check how well you model made the prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Iris Data</b>\n",
    "\n",
    "Here, we classify the flowers in the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression #linear model from sklearn\n",
    "from sklearn.model_selection import train_test_split #help us split data to dependent and independent variables\n",
    "\n",
    "#load dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris_dataset = load_iris() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.4</td>\n",
       "      <td>2.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3\n",
       "0  5.1  3.5  1.4  0.2\n",
       "1  4.9  3.0  1.4  0.2\n",
       "2  4.7  3.2  1.3  0.2\n",
       "3  4.6  3.1  1.5  0.2\n",
       "4  5.0  3.6  1.4  0.2\n",
       "5  5.4  3.9  1.7  0.4\n",
       "6  4.6  3.4  1.4  0.3\n",
       "7  5.0  3.4  1.5  0.2\n",
       "8  4.4  2.9  1.4  0.2\n",
       "9  4.9  3.1  1.5  0.1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#just for the purposes of viewing the dataset\n",
    "from pandas import *\n",
    "dfi = DataFrame(iris_dataset.data)\n",
    "dfi.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kuna/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "y = iris_dataset.target \n",
    "X = iris_dataset.data \n",
    "\n",
    "#split the data into train and test set, use 20% of our dataset for dataset and the remaining 80% for training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Build Logistic Regression Model\n",
    "#create instance of model\n",
    "logr_model = LogisticRegression()\n",
    "\n",
    "#fit the model using the training data\n",
    "logr_model.fit(X_train, y_train)\n",
    "\n",
    "#Predict using the model\n",
    "logr_predict = logr_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Visualization with Seaborn</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer [here](http://localhost:8888/notebooks/Downloads/bertelsmann/logistic-regression-classifier-tutorial%20from%20Kaggle.ipynb) for example on Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#confusion matrix identify % prediction that did not work well\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_predicted)\n",
    "cm\n",
    "\n",
    "#prints the plot of predicted against true \n",
    "import seaborn as sn\n",
    "plt.figure(figsize = (10, 7))\n",
    "sn.heatmap(cm, annot =True)\n",
    "plt.xlabel('predicted')\n",
    "plt.ylabel('Truth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Handling Missing values with Imputer</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Imputer' from 'sklearn.preprocessing' (/home/kuna/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-a4618f992549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mimputer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImputer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'NaN'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'Imputer' from 'sklearn.preprocessing' (/home/kuna/anaconda3/lib/python3.8/site-packages/sklearn/preprocessing/__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(missing_values = 'NaN', strategy = 'mean', axis = '0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
